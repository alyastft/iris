# -*- coding: utf-8 -*-
"""Simple ML Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jp9vqwIuvRye2CZAVkRz3hqPqZU4OjEP

# **Bisnis Understanding**

Description

The sinking of Titanic is one of the most notorious shipwrecks in the history. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.

# **Load Data**
"""

import pandas as pd
import numpy as np

# prompt: give me data from online source
import pandas as pd # Import pandas here
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)
df.head()

# prompt: give me iris dataset

import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target
iris_df.head()

import numpy as np
import pandas as pd
from sklearn import datasets

db = datasets.load_diabetes()
db_array = np.array(db.data)

db

col =["age","sex","bmi","bp_avg","s1_tc","s2_ldl","s3_hdr","s4_tch","s5_ltg","s6_glu"]
df_diabetes = pd.DataFrame(data=db, columns=col)

df_diabetes

db_y = db.target

db_y

"""**SPLITTING DATA**"""

# prompt: give me iris dataset

import pandas as pd
from sklearn.datasets import load_iris, load_diabetes
import numpy as np # Import numpy here
from sklearn.model_selection import train_test_split

# Load the iris dataset
iris = load_iris()
# Create the iris_df DataFrame
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target
iris_df.head()

# The rest of your code for splitting the data should now work

# Splitting the Titanic data
# Ensure 'df' is loaded from a previous cell
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(
    df.drop('Survived', axis=1), df['Survived'], test_size=0.2, random_state=42
)

# Splitting the Iris data
X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(
    iris_df.drop('target', axis=1), iris_df['target'], test_size=0.2, random_state=42
)

# Load and split the Diabetes data in the same cell
db = load_diabetes()
db_array = np.array(db.data)
db_y = db.target

X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(
    db_array, db_y, test_size=0.2, random_state=42
)

print("Titanic data shapes:")
print("X_train:", X_train_titanic.shape)
print("X_test:", X_test_titanic.shape)
print("y_train:", y_train_titanic.shape)
print("y_test:", y_test_titanic.shape)

print("\nIris data shapes:")
print("X_train:", X_train_iris.shape)
print("X_test:", X_test_iris.shape)
print("y_train:", y_train_iris.shape)
print("y_test:", y_test_iris.shape)

print("\nDiabetes data shapes:")
print("X_train:", X_train_diabetes.shape)
print("X_test:", X_test_diabetes.shape)
print("y_train:", y_train_diabetes.shape)
print("y_test:", y_test_diabetes.shape)

# prompt: give me iris dataset

import pandas as pd
from sklearn.datasets import load_iris, load_diabetes
import numpy as np # Import numpy here
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, mean_squared_error


# Load the iris dataset
iris = load_iris()
# Create the iris_df DataFrame
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target
# iris_df.head() # You might not want to display heads inside this combined cell


# Splitting the Titanic data
# Ensure 'df' is loaded from a previous cell
# Assuming df is loaded in an earlier cell
# url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
# df = pd.read_csv(url)
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(
    df.drop('Survived', axis=1), df['Survived'], test_size=0.2, random_state=42
)

# Splitting the Iris data
X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(
    iris_df.drop('target', axis=1), iris_df['target'], test_size=0.2, random_state=42
)

# Load and split the Diabetes data in the same cell
db = load_diabetes()
db_array = np.array(db.data)
db_y = db.target

X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(
    db_array, db_y, test_size=0.2, random_state=42
)

# print("Titanic data shapes:") # You might not want to print shapes inside this combined cell
# print("X_train:", X_train_titanic.shape)
# print("X_test:", X_test_titanic.shape)
# print("y_train:", y_train_titanic.shape)
# print("y_test:", y_test_titanic.shape)

# print("\nIris data shapes:")
# print("X_train:", X_train_iris.shape)
# print("X_test:", X_test_iris.shape)
# print("y_train:", y_train_iris.shape)
# print("y_test:", y_test_iris.shape)

# print("\nDiabetes data shapes:")
# print("X_train:", X_train_diabetes.shape)
# print("X_test:", X_test_diabetes.shape)
# print("y_train:", y_train_diabetes.shape)
# print("y_test:", y_test_diabetes.shape)

# --- Training for Titanic Dataset (Classification) ---
# Since RandomForestClassifier requires numerical input,
# we need to handle categorical features in the Titanic dataset.
# A simple approach is to drop non-numeric columns for this example.
# In a real scenario, you'd use techniques like one-hot encoding.

# Select only numerical columns for the Titanic dataset
titanic_numerical_cols = X_train_titanic.select_dtypes(include=np.number).columns
X_train_titanic_numerical = X_train_titanic[titanic_numerical_cols]
X_test_titanic_numerical = X_test_titanic[titanic_numerical_cols]

# Handle potential NaN values (e.g., simple imputation with the mean)
X_train_titanic_numerical = X_train_titanic_numerical.fillna(X_train_titanic_numerical.mean())
X_test_titanic_numerical = X_test_titanic_numerical.fillna(X_test_titanic_numerical.mean())


print("\n--- Training RandomForestClassifier on Titanic Data ---")
# Initialize the Random Forest Classifier model
rf_classifier_titanic = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_classifier_titanic.fit(X_train_titanic_numerical, y_train_titanic)

# Make predictions on the test set
y_pred_titanic = rf_classifier_titanic.predict(X_test_titanic_numerical)

# Evaluate the model
accuracy_titanic = accuracy_score(y_test_titanic, y_pred_titanic)
print(f"Accuracy on Titanic test set: {accuracy_titanic:.4f}")

# --- Training for Iris Dataset (Classification) ---
print("\n--- Training RandomForestClassifier on Iris Data ---")
# Initialize the Random Forest Classifier model
rf_classifier_iris = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_classifier_iris.fit(X_train_iris, y_train_iris)

# Make predictions on the test set
y_pred_iris = rf_classifier_iris.predict(X_test_iris)

# Evaluate the model
accuracy_iris = accuracy_score(y_test_iris, y_pred_iris)
print(f"Accuracy on Iris test set: {accuracy_iris:.4f}")

# --- Training for Diabetes Dataset (Regression) ---
print("\n--- Training RandomForestRegressor on Diabetes Data ---")
# Initialize the Random Forest Regressor model
rf_regressor_diabetes = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf_regressor_diabetes.fit(X_train_diabetes, y_train_diabetes)

# Make predictions on the test set
y_pred_diabetes = rf_regressor_diabetes.predict(X_test_diabetes)

# Evaluate the model using Mean Squared Error
mse_diabetes = mean_squared_error(y_test_diabetes, y_pred_diabetes)
print(f"Mean Squared Error on Diabetes test set: {mse_diabetes:.4f}")

# prompt: create code for training using naive bayes

from sklearn.naive_bayes import GaussianNB

# --- Training using Naive Bayes for Classification datasets ---

# Naive Bayes on Titanic Data (Classification)
# We will use the same numerical data subset prepared for RandomForestClassifier
print("\n--- Training Gaussian Naive Bayes on Titanic Data ---")
# Initialize the Gaussian Naive Bayes model
nb_classifier_titanic = GaussianNB()

# Train the model
nb_classifier_titanic.fit(X_train_titanic_numerical, y_train_titanic)

# Make predictions on the test set
y_pred_nb_titanic = nb_classifier_titanic.predict(X_test_titanic_numerical)

# Evaluate the model
accuracy_nb_titanic = accuracy_score(y_test_titanic, y_pred_nb_titanic)
print(f"Accuracy (Naive Bayes) on Titanic test set: {accuracy_nb_titanic:.4f}")

# Naive Bayes on Iris Data (Classification)
print("\n--- Training Gaussian Naive Bayes on Iris Data ---")
# Initialize the Gaussian Naive Bayes model
nb_classifier_iris = GaussianNB()

# Train the model
nb_classifier_iris.fit(X_train_iris, y_train_iris)

# Make predictions on the test set
y_pred_nb_iris = nb_classifier_iris.predict(X_test_iris)

# Evaluate the model
accuracy_nb_iris = accuracy_score(y_test_iris, y_pred_nb_iris)
print(f"Accuracy (Naive Bayes) on Iris test set: {accuracy_nb_iris:.4f}")

# Naive Bayes is typically used for classification.
# While there are adaptations for regression, the standard Gaussian Naive Bayes
# from scikit-learn is for classification.
# Therefore, we won't apply it directly to the Diabetes (regression) dataset
# using the standard GaussianNB.
# If needed for regression, one would explore different naive bayes implementations
# or transformation of the problem (e.g., predicting categories based on target ranges).